{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Imagenette\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from basic_cnn import BasicCNN  # Make sure to import your model here\n",
    "\n",
    "# Prepare the dataset\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    transforms.Grayscale()\n",
    "])\n",
    "\n",
    "train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=True, transform=train_transforms)\n",
    "\n",
    "# Use 10% of the training set for validation\n",
    "train_set_size = int(len(train_dataset) * 0.9)\n",
    "val_set_size = len(train_dataset) - train_set_size\n",
    "\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_set_size, val_set_size], generator=seed)\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "\n",
    "# Use DataLoader to load the dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, num_workers=8, shuffle=False)\n",
    "\n",
    "# Configure the test dataset\n",
    "test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=True, transform=test_transforms)\n",
    "\n",
    "# Initialize the model\n",
    "model = BasicCNN()\n",
    "\n",
    "# Add EarlyStopping\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "# Configure Checkpoints\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], max_epochs=50, accelerator=\"gpu\")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)\n",
    "test_results = trainer.test(model=model, dataloaders=test_loader)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training and Validation Metrics:\")\n",
    "print(f\"Training Loss: {trainer.callback_metrics.get('train_loss', 'N/A')}\")\n",
    "print(f\"Validation Loss: {trainer.callback_metrics.get('val_loss', 'N/A')}\")\n",
    "print(f\"Validation Accuracy: {trainer.callback_metrics.get('val_accuracy', 'N/A')}\")\n",
    "\n",
    "print(\"Test Metrics:\")\n",
    "for result in test_results:\n",
    "    print(f\"Test Accuracy: {result.get('test_accuracy', 'N/A')}\")\n",
    "    print(f\"Test Loss: {result.get('test_loss', 'N/A')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse6363a4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
