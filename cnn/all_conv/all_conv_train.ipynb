{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import pytorch_lightning as L\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Imagenette\n",
    "from torch.utils.data import DataLoader\n",
    "from all_conv_model import AllConvNet\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = Imagenette(\"data/imagenette/train/\", split=\"train\", size=\"160px\", download=True, transform=train_transforms)\n",
    "val_set_size = int(len(train_dataset) * 0.1)\n",
    "train_set_size = len(train_dataset) - val_set_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_set_size, val_set_size])\n",
    "val_dataset.dataset.transform = test_transforms\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dataset = Imagenette(\"data/imagenette/test/\", split=\"val\", size=\"160px\", download=True, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = 10\n",
    "model = AllConvNet(num_classes=num_classes)\n",
    "\n",
    "# Set up early stopping and checkpoint callbacks\n",
    "early_stop_callback = L.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True, mode=\"min\")\n",
    "checkpoint_callback = L.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = L.Trainer(callbacks=[early_stop_callback, checkpoint_callback], max_epochs=50, accelerator=\"gpu\")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = trainer.test(model=model, dataloaders=val_loader)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training and Validation Metrics:\")\n",
    "print(f\"Training Loss: {trainer.callback_metrics.get('train_loss', 'Not Available')}\")\n",
    "print(f\"Validation Loss: {trainer.callback_metrics.get('val_loss', 'Not Available')}\")\n",
    "print(f\"Validation Accuracy: {trainer.callback_metrics.get('val_accuracy', 'Not Available')}\")\n",
    "\n",
    "# Print test results\n",
    "print(f\"Test Loss: {test_results[0]['test_loss'] if 'test_loss' in test_results[0] else 'Not Available'}\")\n",
    "print(f\"Test Accuracy: {test_results[0]['test_accuracy'] if 'test_accuracy' in test_results[0] else 'Not Available'}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
